<!DOCTYPE html><html lang="zh_CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>tiaotiaohuの98 | tiaotiaohuの98</title><meta name="author" content="tiaotiaohu"><meta name="copyright" content="tiaotiaohu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="无标题页面 - wolai 笔记title: 第7节_支持向量机categories: 机器学习笔记上篇主要介绍了神经网络。首先从生物学神经元出发，引出了它的数学抽象模型--MP神经元以及由两层神经元组成的感知机模型，并基于梯度下降的方法描述了感知机模型的权值调整规则。由于简单的感知机不能处理线性不可分的情形，因此接着引入了含隐层的前馈型神经网络，BP神经网络则是其中最为成功的一种学习方法，它使">
<meta property="og:type" content="website">
<meta property="og:title" content="tiaotiaohuの98">
<meta property="og:url" content="https://tiaotiaohu98.github.io/machineLearning/ML/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(7)--%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html">
<meta property="og:site_name" content="tiaotiaohuの98">
<meta property="og:description" content="无标题页面 - wolai 笔记title: 第7节_支持向量机categories: 机器学习笔记上篇主要介绍了神经网络。首先从生物学神经元出发，引出了它的数学抽象模型--MP神经元以及由两层神经元组成的感知机模型，并基于梯度下降的方法描述了感知机模型的权值调整规则。由于简单的感知机不能处理线性不可分的情形，因此接着引入了含隐层的前馈型神经网络，BP神经网络则是其中最为成功的一种学习方法，它使">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2022-08-30T12:22:13.661Z">
<meta property="article:modified_time" content="2022-08-30T04:21:20.000Z">
<meta property="article:author" content="tiaotiaohu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://tiaotiaohu98.github.io/machineLearning/ML/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(7)--%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: tiaotiaohu","link":"链接: ","source":"来源: tiaotiaohuの98","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'tiaotiaohuの98',
  isPost: false,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-30 12:21:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">articles</div><div class="length-num">18</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">tags</div><div class="length-num">0</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">categories</div><div class="length-num">1</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/machineLearning/machineLearning"><i class="fa-fw fas fa-machineLearning"></i><span> 机器学习</span></a></li><li><a class="site-page child" href="/KG/KG"><i class="fa-fw fas fa-KG"></i><span> 知识图谱</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">tiaotiaohuの98</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/machineLearning/machineLearning"><i class="fa-fw fas fa-machineLearning"></i><span> 机器学习</span></a></li><li><a class="site-page child" href="/KG/KG"><i class="fa-fw fas fa-KG"></i><span> 知识图谱</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="page"><h1 class="page-title"></h1><div id="article-container"><!DOCTYPE html>
<html lang="zh-Hans-CN"><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=Edge"/><link rel="stylesheet" type="text/css" href="css/modern-norm.min.css"/><link rel="stylesheet" type="text/css" href="css/prism.min.css"/><link rel="stylesheet" type="text/css" href="css/katex.min.css"/><link rel="stylesheet" type="text/css" href="css/wolai.css"/><title>无标题页面 - wolai 笔记</title><link rel="shortcut icon" href="data:image/svg+xml,%3Csvg xmlns=&apos;http://www.w3.org/2000/svg&apos; viewBox=&apos;0 0 800 800&apos;%3E%3Cdefs%3E%3Cstyle%3E.cls-1%7Bfill:%23fff;%7D%3C/style%3E%3C/defs%3E%3Cg%3E%3Cpath class=&apos;cls-1&apos; d=&apos;M610.08,0c66,0,90,6.88,114.13,19.79a134.62,134.62,0,0,1,56,56l2.28,4.4C793.93,103,800,127.88,800,189.92V610.08l-.08,11.56c-.78,57.38-7.58,79.89-19.71,102.57a134.62,134.62,0,0,1-56,56l-4.4,2.28C697,793.93,672.12,800,610.08,800H189.92l-11.56-.08c-57.38-.78-79.89-7.58-102.57-19.71a134.62,134.62,0,0,1-56-56l-2.28-4.4C6.44,697.75.4,673.72,0,616L0,189.92c0-66,6.88-90,19.79-114.13a134.62,134.62,0,0,1,56-56l4.4-2.28C102.25,6.44,126.28.4,184,0Z&apos;/%3E%3Cpath d=&apos;M610.08,0c66,0,90,6.88,114.13,19.79a134.62,134.62,0,0,1,56,56l2.28,4.4C793.93,103,800,127.88,800,189.92V610.08l-.08,11.56c-.78,57.38-7.58,79.89-19.71,102.57a134.62,134.62,0,0,1-56,56l-4.4,2.28C697,793.93,672.12,800,610.08,800H189.92l-11.56-.08c-57.38-.78-79.89-7.58-102.57-19.71a134.62,134.62,0,0,1-56-56l-2.28-4.4C6.44,697.75.4,673.72,0,616L0,189.92c0-66,6.88-90,19.79-114.13a134.62,134.62,0,0,1,56-56l4.4-2.28C102.25,6.44,126.28.4,184,0Zm4.72,88.9H185.2L172.42,89c-32.78.62-43.68,3.24-54.71,9.14a45.84,45.84,0,0,0-19.54,19.54c-6.61,12.36-9.11,24.55-9.27,67.49V614.8L89,627.58c.62,32.78,3.24,43.68,9.14,54.71a45.84,45.84,0,0,0,19.54,19.54c12.36,6.61,24.55,9.11,67.49,9.27H610.08c46.79,0,59.41-2.44,72.21-9.28a45.84,45.84,0,0,0,19.54-19.54c6.61-12.36,9.11-24.55,9.27-67.49V189.92c0-46.79-2.44-59.41-9.28-72.21a45.84,45.84,0,0,0-19.54-19.54C669.93,91.56,657.74,89.06,614.8,88.9ZM233.33,493.33A73.34,73.34,0,1,1,160,566.67,73.35,73.35,0,0,1,233.33,493.33Z&apos;/%3E%3C/g%3E%3C/svg%3E"></link></head><body><header><div class="image"></div><div class="title"><div class="banner"><div class="icon"></div></div><div data-title="新页面" class="main-title placeholder"></div></div></header><article><hr id="38dJvdP6pcykSCAopM2umj" class="wolai-block"/><div id="3dcg8Vf4BVNN8SDsEr3e9v" class="wolai-block wolai-text"><div><span class="inline-wrap">title: 第<span class="jill"></span>7<span class="jill"></span>节_支持向量机</span></div></div><div id="f42RdGJpBRpgJD8dmthTT2" class="wolai-block wolai-text"><div><span class="inline-wrap">categories: 机器学习笔记</span></div></div><hr id="aigYACsEvv6YssLcdrVKip" class="wolai-block"/><div id="epeVJiBLwiy7mhgoXMgHgt" class="wolai-block wolai-text"><div><span class="inline-wrap">上篇主要介绍了神经网络。首先从生物学神经元出发，引出了它的数学抽象模型--MP<span class="jill"></span>神经元以及由两层神经元组成的感知机模型，并基于梯度下降的方法描述了感知机模型的权值调整规则。由于简单的感知机不能处理线性不可分的情形，因此接着引入了含隐层的前馈型神经网络，BP<span class="jill"></span>神经网络则是其中最为成功的一种学习方法，它使用误差逆传播的方法来逐层调节连接权。最后简单介绍了局部/全局最小以及目前十分火热的深度学习的概念。本篇围绕的核心则是曾经一度取代过神经网络的另一种监督学习算法--</span><span class="inline-wrap"><b>支持向量机</b></span><span class="inline-wrap">（Support Vector Machine），简称</span><span class="inline-wrap"><b>SVM</b></span><span class="inline-wrap">。</span></div></div><h1 id="vSCYiiP6CwnqDt4iDTbJkD" class="wolai-block"><span class="inline-wrap"><b>6、支持向量机</b></span></h1><div id="vF6BpQ6BMQXgCjG2DWLwEf" class="wolai-block wolai-text"><div><span class="inline-wrap">支持向量机是一种经典的二分类模型，基本模型定义为特征空间中最大间隔的线性分类器，其学习的优化目标便是间隔最大化，因此支持向量机本身可以转化为一个凸二次规划求解的问题。</span></div></div><div id="9vYtM9jCSnqF3JPaTdTiSZ" class="wolai-block wolai-text"><div><span class="inline-wrap">##</span><span class="inline-wrap"><b>6.1 函数间隔与几何间隔</b></span></div></div><div id="sPbe62tNdqY6HuaUCWykHa" class="wolai-block wolai-text"><div><span class="inline-wrap">对于二分类学习，假设现在的数据是线性可分的，这时分类学习最基本的想法就是找到一个合适的超平面，该超平面能够将不同类别的样本分开，类似二维平面使用<span class="jill"></span>ax+by+c=0<span class="jill"></span>来表示，超平面实际上表示的就是高维的平面，如下图所示：</span></div></div><div id="gTiTz8wq1eoZLSRZ3uLtSx" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f6a2ec8a.png" style="width: 363px"/></figure></div><div id="k9D7LGY8eyCv89Q5NzEXyA" class="wolai-block wolai-text"><div><span class="inline-wrap">对数据点进行划分时，易知：当超平面距离与它最近的数据点的间隔越大，分类的鲁棒性越好，即当新的数据点加入时，超平面对这些点的适应性最强，出错的可能性最小。因此需要让所选择的超平面能够最大化这个间隔<span class="jill"></span>Gap（如下图所示）， 常用的间隔定义有两种，一种称之为函数间隔，一种为几何间隔，下面将分别介绍这两种间隔，并对<span class="jill"></span>SVM<span class="jill"></span>为什么会选用几何间隔做了一些阐述。</span></div></div><div id="eybpNXz3W9XgLiXRKYX7pe" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f6a06d5a.png" style="width: 428px"/></figure></div><div id="r3Z5BiaYxL2iTKMbH2QrQX" class="wolai-block wolai-text"><div><span class="inline-wrap">###</span><span class="inline-wrap"><b>6.1.1 函数间隔</b></span></div></div><div id="faw1XmBC4HdyApacQ5MeBM" class="wolai-block wolai-text"><div><span class="inline-wrap">在超平面<span class="jill"></span>w&#39;x+b=0<span class="jill"></span>确定的情况下，|w&#39;x*+b|<span class="jill"></span>能够代表点<span class="jill"></span>x</span><span class="inline-wrap"><i>距离超平面的远近，易知：当<span class="jill"></span>w&#39;x</i></span><span class="inline-wrap">+b&gt;0<span class="jill"></span>时，表示<span class="jill"></span>x</span><span class="inline-wrap"><i>在超平面的一侧（正类，类标为<span class="jill"></span>1），而当<span class="jill"></span>w&#39;x</i></span><span class="inline-wrap">+b&lt;0<span class="jill"></span>时，则表示<span class="jill"></span>x</span><span class="inline-wrap"><i>在超平面的另外一侧（负类，类别为-1），因此（w&#39;x</i></span><span class="inline-wrap">+b）y* 的正负性恰能表示数据点<span class="jill"></span>x*是否被分类正确。于是便引出了</span><span class="inline-wrap"><b>函数间隔</b></span><span class="inline-wrap">的定义（functional margin）:</span></div></div><div id="w4apz2jRKsxcpi1gHBGg3K" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f690a14b.png" style="width: 346px"/></figure></div><div id="h2wseSPbF9NN9RP4SEE8E" class="wolai-block wolai-text"><div><span class="inline-wrap">而超平面（w,b）关于所有样本点（Xi，Yi）的函数间隔最小值则为超平面在训练数据集<span class="jill"></span>T<span class="jill"></span>上的函数间隔：</span></div></div><div id="hVCLJMU259fYao5af8ZTdb" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f690ac26.png" style="width: 322px"/></figure></div><div id="mEv7hRrMJXzS4kL6cSDjTv" class="wolai-block wolai-text"><div><span class="inline-wrap">可以看出：这样定义的函数间隔在处理<span class="jill"></span>SVM<span class="jill"></span>上会有问题，当超平面的两个参数<span class="jill"></span>w<span class="jill"></span>和<span class="jill"></span>b<span class="jill"></span>同比例改变时，函数间隔也会跟着改变，但是实际上超平面还是原来的超平面，并没有变化。例如：w1x1+w2x2+w3x3+b=0<span class="jill"></span>其实等价于<span class="jill"></span>2w1x1+2w2x2+2w3x3+2b=0，但计算的函数间隔却翻了一倍。从而引出了能真正度量点到超平面距离的概念--几何间隔（geometrical margin）。</span></div></div><h3 id="ojzQdbYypTzqJfCzEW9XQx" class="wolai-block"><span class="inline-wrap"><b>6.1.2 几何间隔</b></span></h3><div id="okZRg3HR4f7Amm5XsF2rNd" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>几何间隔</b></span><span class="inline-wrap">代表的则是数据点到超平面的真实距离，对于超平面<span class="jill"></span>w&#39;x+b=0，w<span class="jill"></span>代表的是该超平面的法向量，设<span class="jill"></span>x</span><span class="inline-wrap"><i>为超平面外一点<span class="jill"></span>x<span class="jill"></span>在法向量<span class="jill"></span>w<span class="jill"></span>方向上的投影点，x<span class="jill"></span>与超平面的距离为<span class="jill"></span>r，则有<span class="jill"></span>x</i></span><span class="inline-wrap">=x-r(w/||w||)，又<span class="jill"></span>x</span><span class="inline-wrap"><i>在超平面上，即<span class="jill"></span>w&#39;x</i></span><span class="inline-wrap">+b=0，代入即可得：</span></div></div><div id="9JqsR4Nah5imnuLw2xLX62" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f697d499.png" style="width: 324px"/></figure></div><div id="9TBveeTFy11XQzgmh29L8W" class="wolai-block wolai-text"><div><span class="inline-wrap">为了得到<span class="jill"></span>r<span class="jill"></span>的绝对值，令<span class="jill"></span>r<span class="jill"></span>呈上其对应的类别<span class="jill"></span>y，即可得到几何间隔的定义：</span></div></div><div id="nssY12PSsJ4NKoebfxn5EV" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f696fd10.png" style="width: 266px"/></figure></div><div id="2Gq7A1JgB2fMg9fJgNmdf4" class="wolai-block wolai-text"><div><span class="inline-wrap">从上述函数间隔与几何间隔的定义可以看出：实质上函数间隔就是<span class="jill"></span>|w&#39;x+b|，而几何间隔就是点到超平面的距离。</span></div></div><div id="kRv3MaRCQ7XrghqRALqSPp" class="wolai-block wolai-text"><div><span class="inline-wrap">##</span><span class="inline-wrap"><b>6.2 最大间隔与支持向量</b></span></div></div><div id="pVQSRs9MkCf4a9otPq2Hxx" class="wolai-block wolai-text"><div><span class="inline-wrap">通过前面的分析可知：函数间隔不适合用来最大化间隔，因此这里我们要找的最大间隔指的是几何间隔，于是最大间隔分类器的目标函数定义为：</span></div></div><div id="887CQGqBvB8dTKgD29WWNA" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f69af163.png" style="width: 505px"/></figure></div><div id="iR3HiD4cgyEkrxdKd3pbCz" class="wolai-block wolai-text"><div><span class="inline-wrap">一般地，我们令<span class="jill"></span>r^为<span class="jill"></span>1（这样做的目的是为了方便推导和目标函数的优化），从而上述目标函数转化为：</span></div></div><div id="8fonpW52ia76kWRgz5SC8T" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f697bb1d.png" style="width: 547px"/></figure></div><div id="37uqP8WNSVPPu1bZqDHFvN" class="wolai-block wolai-text"><div><span class="inline-wrap">对于<span class="jill"></span>y(w&#39;x+b)=1<span class="jill"></span>的数据点，即下图中位于<span class="jill"></span>w&#39;x+b=1<span class="jill"></span>或<span class="jill"></span>w&#39;x+b=-1<span class="jill"></span>上的数据点，我们称之为</span><span class="inline-wrap"><b>支持向量</b></span><span class="inline-wrap">（support vector），易知：对于所有的支持向量，它们恰好满足<span class="jill"></span>y*(w&#39;x*+b)=1，而所有不是支持向量的点，有<span class="jill"></span>y*(w&#39;x*+b)&gt;1。</span></div></div><div id="xhK4YpkBM3gwnqB7DsrNGT" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f6a838c4.png" style="width: 750px"/></figure></div><h2 id="47hJou18oQfsLoneu6769g" class="wolai-block"><span class="inline-wrap"><b>6.3 从原始优化问题到对偶问题</b></span></h2><div id="r4iPDuj5nLBXxptxbCBTXQ" class="wolai-block wolai-text"><div><span class="inline-wrap">对于上述得到的目标函数，求<span class="jill"></span>1/||w||<span class="jill"></span>的最大值相当于求<span class="jill"></span>||w||^2<span class="jill"></span>的最小值，因此很容易将原来的目标函数转化为：</span></div></div><div id="gcwy5tABGCjWWc6tJTBkin" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f6978cbb.png" style="width: 643px"/></figure></div><div id="onnTZHLCzo34TbscfGwUKZ" class="wolai-block wolai-text"><div><span class="inline-wrap">即变为了一个带约束的凸二次规划问题，按书上所说可以使用现成的优化计算包（QP<span class="jill"></span>优化包）求解，但由于<span class="jill"></span>SVM<span class="jill"></span>的特殊性，一般我们将原问题变换为它的</span><span class="inline-wrap"><b>对偶问题</b></span><span class="inline-wrap">，接着再对其对偶问题进行求解。为什么通过对偶问题进行求解，有下面两个原因：</span></div><ul class="wolai-block"><li id="nBJyMB3pevoNKYAHz4cveQ"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">一是因为使用对偶问题更容易求解；</span></li><li id="p3wg775AtZ289HZ51PPQAX"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">二是因为通过对偶问题求解出现了向量内积的形式，从而能更加自然地引出核函数。</span></li></ul></div><div id="nhZdZHcU2ADpdQvtpfwuHd" class="wolai-block wolai-text"><div><span class="inline-wrap">对偶问题，顾名思义，可以理解成优化等价的问题，更一般地，是将一个原始目标函数的最小化转化为它的对偶函数最大化的问题。对于当前的优化问题，首先我们写出它的朗格朗日函数：</span></div></div><div id="pbGQ8uZUTGKu7u2oivQnoL" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f9332be7.png" style="width: 590px"/></figure></div><div id="7cdft2MoaAP3ZL9faZYDwT" class="wolai-block wolai-text"><div><span class="inline-wrap">上式很容易验证：当其中有一个约束条件不满足时，L<span class="jill"></span>的最大值为 ∞（只需令其对应的<span class="jill"></span>α<span class="jill"></span>为 ∞即可）；当所有约束条件都满足时，L<span class="jill"></span>的最大值为<span class="jill"></span>1/2||w||^2（此时令所有的<span class="jill"></span>α<span class="jill"></span>为<span class="jill"></span>0），因此实际上原问题等价于：</span></div></div><div id="e6zEgz3HQcQznPwupjV7qA" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f93321c5.png" style="width: 456px"/></figure></div><div id="7MkTfRDX8s8o7UJmkqdNvC" class="wolai-block wolai-text"><div><span class="inline-wrap">由于这个的求解问题不好做，因此一般我们将最小和最大的位置交换一下（需满足<span class="jill"></span>KKT<span class="jill"></span>条件） ，变成原问题的对偶问题：</span></div></div><div id="u3SxcUBsKGuLoDzFDz8H6H" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f9330967.png" style="width: 307px"/></figure></div><div id="msQtVAP1FtgAPe2iXrJ3jd" class="wolai-block wolai-text"><div><span class="inline-wrap">这样就将原问题的求最小变成了对偶问题求最大（用对偶这个词还是很形象），接下来便可以先求<span class="jill"></span>L<span class="jill"></span>对<span class="jill"></span>w<span class="jill"></span>和<span class="jill"></span>b<span class="jill"></span>的极小，再求<span class="jill"></span>L<span class="jill"></span>对<span class="jill"></span>α<span class="jill"></span>的极大。</span></div></div><div id="vcjApRjut5FZxYWntsHC46" class="wolai-block wolai-text"><div><span class="inline-wrap">（1）首先求<span class="jill"></span>L<span class="jill"></span>对<span class="jill"></span>w<span class="jill"></span>和<span class="jill"></span>b<span class="jill"></span>的极小，分别求<span class="jill"></span>L<span class="jill"></span>关于<span class="jill"></span>w<span class="jill"></span>和<span class="jill"></span>b<span class="jill"></span>的偏导，可以得出：</span></div></div><div id="MT4E692pxSfKWZPqWXKyX" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f9333e66.png" style="width: 344px"/></figure></div><div id="9Yr2BnYPqdRiZyZcxGReht" class="wolai-block wolai-text"><div><span class="inline-wrap">将上述结果代入<span class="jill"></span>L<span class="jill"></span>得到：</span></div></div><div id="5HE38mKYzokSP3GiQrexXa" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f935ae21.png" style="width: 864px"/></figure></div><div id="3S2DRSKw6TWtgp9JAKBCTf" class="wolai-block wolai-text"><div><span class="inline-wrap">（2）接着<span class="jill"></span>L<span class="jill"></span>关于<span class="jill"></span>α<span class="jill"></span>极大求解<span class="jill"></span>α（通过<span class="jill"></span>SMO<span class="jill"></span>算法求解，此处不做深入）。</span></div></div><div id="rx3Z2TTduizyMS61gHJ1gU" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f9338a9d.png" style="width: 466px"/></figure></div><div id="vmcLscWyLKQNxa9EVK7EC1" class="wolai-block wolai-text"><div><span class="inline-wrap">（3）最后便可以根据求解出的<span class="jill"></span>α，计算出<span class="jill"></span>w<span class="jill"></span>和<span class="jill"></span>b，从而得到分类超平面函数。</span></div></div><div id="mD82ZLonSykYSBgJu6RdU5" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f93419ca.png" style="width: 543px"/></figure></div><div id="8UNADuBd135riZPD3hKnHL" class="wolai-block wolai-text"><div><span class="inline-wrap">在对新的点进行预测时，实际上就是将数据点<span class="jill"></span>x*代入分类函数<span class="jill"></span>f(x)=w&#39;x+b<span class="jill"></span>中，若<span class="jill"></span>f(x)&gt;0，则为正类，f(x)&lt;0，则为负类，根据前面推导得出的<span class="jill"></span>w<span class="jill"></span>与<span class="jill"></span>b，分类函数如下所示，此时便出现了上面所提到的内积形式。</span></div></div><div id="cc2Uo7LH5mcK7R5tJwjqdB" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f9353166.png" style="width: 391px"/></figure></div><div id="5w74fNFX6fVxpd7LbcF1pq" class="wolai-block wolai-text"><div><span class="inline-wrap">这里实际上只需计算新样本与支持向量的内积，因为对于非支持向量的数据点，其对应的拉格朗日乘子一定为<span class="jill"></span>0，根据最优化理论（K-T<span class="jill"></span>条件），对于不等式约束<span class="jill"></span>y(w&#39;x+b)-1≥0，满足：</span></div></div><div id="ud9tDcXrNdbfhKRqggqFfS" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f933c947.png" style="width: 471px"/></figure></div><h2 id="t6Mf1DWN1Vms2qQ6LQ9wva" class="wolai-block"><span class="inline-wrap"><b>6.4 核函数</b></span></h2><div id="hTqFwcyPCdB9Jt4wHnYmEz" class="wolai-block wolai-text"><div><span class="inline-wrap">由于上述的超平面只能解决线性可分的问题，对于线性不可分的问题，例如：异或问题，我们需要使用核函数将其进行推广。一般地，解决线性不可分问题时，常常采用</span><span class="inline-wrap"><b>映射</b></span><span class="inline-wrap">的方式，将低维原始空间映射到高维特征空间，使得数据集在高维空间中变得线性可分，从而再使用线性学习器分类。如果原始空间为有限维，即属性数有限，那么总是存在一个高维特征空间使得样本线性可分。若∅代表一个映射，则在特征空间中的划分函数变为：</span></div></div><div id="ZV7GaLMXgXSanAze7DRh7" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc72f934303e.png" style="width: 226px"/></figure></div><div id="a3wHP5croGQ9yDSj5GEA4k" class="wolai-block wolai-text"><div><span class="inline-wrap">按照同样的方法，先写出新目标函数的拉格朗日函数，接着写出其对偶问题，求<span class="jill"></span>L<span class="jill"></span>关于<span class="jill"></span>w<span class="jill"></span>和<span class="jill"></span>b<span class="jill"></span>的极大，最后运用<span class="jill"></span>SOM<span class="jill"></span>求解<span class="jill"></span>α。可以得出：</span></div></div><div id="chPkJ7q41iJqYDWtA3PFgL" class="wolai-block wolai-text"><div><span class="inline-wrap">（1）原对偶问题变为：</span></div></div><div id="gBEqSZ2bh4qv7RKR9yuawP" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730cc68b3b.png" style="width: 546px"/></figure></div><div id="cnYSgV7RtrPrSUmCMoWdus" class="wolai-block wolai-text"><div><span class="inline-wrap">（2）原分类函数变为：</span></div><div id="dj9G1LCUnwXYdazCL5iFG5" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730cc1b673.png" style="width: 401px"/></figure></div></div><div id="k19ZteLk4g75m2D25Yuh74" class="wolai-block wolai-text"><div><span class="inline-wrap">求解的过程中，只涉及到了高维特征空间中的内积运算，由于特征空间的维数可能会非常大，例如：若原始空间为二维，映射后的特征空间为<span class="jill"></span>5<span class="jill"></span>维，若原始空间为三维，映射后的特征空间将是<span class="jill"></span>19<span class="jill"></span>维，之后甚至可能出现无穷维，根本无法进行内积运算了，此时便引出了</span><span class="inline-wrap"><b>核函数</b></span><span class="inline-wrap">（Kernel）的概念。</span></div></div><div id="sU9CkFRW8zWA3uDg7Guwqs" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730cc49adc.png" style="width: 1035px"/></figure></div><div id="sxk6b5erV8Uqg8rtuk65Mc" class="wolai-block wolai-text"><div><span class="inline-wrap">因此，核函数可以直接计算隐式映射到高维特征空间后的向量内积，而不需要显式地写出映射后的结果，它虽然完成了将特征从低维到高维的转换，但最终却是在低维空间中完成向量内积计算，与高维特征空间中的计算等效</span><span class="inline-wrap"><b>（低维计算，高维表现）</b></span><span class="inline-wrap">，从而避免了直接在高维空间无法计算的问题。引入核函数后，原来的对偶问题与分类函数则变为：</span></div></div><div id="j9rrHHnohWY9eAjAAvW1u9" class="wolai-block wolai-text"><div><span class="inline-wrap">（1）对偶问题：</span></div></div><div id="5HSZViAYGG74WutGcZisFt" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730cc173b2.png" style="width: 512px"/></figure></div><div id="2rfBUxnK17z4AdyNeSNjsr" class="wolai-block wolai-text"><div><span class="inline-wrap">（2）分类函数：</span></div></div><div id="vaMx4ZzUGFdmBTVpKQozDs" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730cc05959.png" style="width: 348px"/></figure></div><div id="ntGcVEJhuzudaTYB9oEBcc" class="wolai-block wolai-text"><div><span class="inline-wrap">因此，在线性不可分问题中，核函数的选择成了支持向量机的最大变数，若选择了不合适的核函数，则意味着将样本映射到了一个不合适的特征空间，则极可能导致性能不佳。同时，核函数需要满足以下这个必要条件：</span></div></div><div id="fR1bvHeygLfLa1gQBttC8B" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730ccc468c.png" style="width: 771px"/></figure></div><div id="j7xvDhc83K9mQmxH5CyrHi" class="wolai-block wolai-text"><div><span class="inline-wrap">由于核函数的构造十分困难，通常我们都是从一些常用的核函数中选择，下面列出了几种常用的核函数：</span></div></div><div id="9wb8Lngtb5BUFDGR3G478H" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730ccc541a.png" style="width: 788px"/></figure></div><h2 id="2tNf1KaJcSqnsq6VEXvsXJ" class="wolai-block"><span class="inline-wrap"><b>6.5 软间隔支持向量机</b></span></h2><div id="6WdLRyWuceXaKenCEQ11cx" class="wolai-block wolai-text"><div><span class="inline-wrap">前面的讨论中，我们主要解决了两个问题：当数据线性可分时，直接使用最大间隔的超平面划分；当数据线性不可分时，则通过核函数将数据映射到高维特征空间，使之线性可分。然而在现实问题中，对于某些情形还是很难处理，例如数据中有</span><span class="inline-wrap"><b>噪声</b></span><span class="inline-wrap">的情形，噪声数据（</span><span class="inline-wrap"><b>outlier</b></span><span class="inline-wrap">）本身就偏离了正常位置，但是在前面的<span class="jill"></span>SVM<span class="jill"></span>模型中，我们要求所有的样本数据都必须满足约束，如果不要这些噪声数据还好，当加入这些<span class="jill"></span>outlier<span class="jill"></span>后导致划分超平面被挤歪了，如下图所示，对支持向量机的泛化性能造成很大的影响。</span></div></div><div id="hCTG2C3SSME7FWBqtDEyRD" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730ccce68e.png" style="width: 578px"/></figure></div><div id="kNgTFKN26DPrBE5jub5Ehh" class="wolai-block wolai-text"><div><span class="inline-wrap">为了解决这一问题，我们需要允许某一些数据点不满足约束，即可以在一定程度上偏移超平面，同时使得不满足约束的数据点尽可能少，这便引出了</span><span class="inline-wrap"><b>“软间隔”支持向量机</b></span><span class="inline-wrap">的概念</span></div><ul class="wolai-block"><li id="kfFvtiMiQSRJ3aSY1DQoBr"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">允许某些数据点不满足约束<span class="jill"></span>y(w&#39;x+b)≥1；</span></li></ul></div><ul class="wolai-block"><li id="gMDJ3tSW1PQp7KmVcoqby3"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">同时又使得不满足约束的样本尽可能少。</span></li></ul><div id="cTJBuGNhXe41QoHNhGhm1G" class="wolai-block wolai-text"><div><span class="inline-wrap">这样优化目标变为：</span></div></div><div id="gkD8JCLZvmcZqXgtP9ScR2" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730cc6c9fe.png" style="width: 457px"/></figure></div><div id="s4MxpKuXBYksXXgPSxCS6G" class="wolai-block wolai-text"><div><span class="inline-wrap">如同阶跃函数，0/1<span class="jill"></span>损失函数虽然表示效果最好，但是数学性质不佳。因此常用其它函数作为“替代损失函数”。</span></div></div><div id="by2SEQ8YgM7bWcKhHcMFqd" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc730cc5e5a9.png" style="width: 547px"/></figure></div><div id="ushxLSTiSPb5xdn6r8MDx2" class="wolai-block wolai-text"><div><span class="inline-wrap">支持向量机中的损失函数为</span><span class="inline-wrap"><b>hinge<span class="jill"></span>损失</b></span><span class="inline-wrap">，引入</span><span class="inline-wrap"><b>“松弛变量”</b></span><span class="inline-wrap">，目标函数与约束条件可以写为：</span></div></div><div id="9M4JBygZtHgzkHwX4Dd2U8" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc7317aa3411.png" style="width: 451px"/></figure></div><div id="pE21KssxfsP2mKJcfp8rz7" class="wolai-block wolai-text"><div><span class="inline-wrap">其中<span class="jill"></span>C<span class="jill"></span>为一个参数，控制着目标函数与新引入正则项之间的权重，这样显然每个样本数据都有一个对应的松弛变量，用以表示该样本不满足约束的程度，将新的目标函数转化为拉格朗日函数得到：</span></div></div><div id="iQhnb8iwjQnf2gc5qPrg8v" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc7317a4c96e.png" style="width: 885px"/></figure></div><div id="25LFr2SaTDrsTSjQv3LTiY" class="wolai-block wolai-text"><div><span class="inline-wrap">按照与之前相同的方法，先让<span class="jill"></span>L<span class="jill"></span>求关于<span class="jill"></span>w，b<span class="jill"></span>以及松弛变量的极小，再使用<span class="jill"></span>SMO<span class="jill"></span>求出<span class="jill"></span>α，有：</span></div></div><div id="cNcqn3fHndZG2zvuRj2yYW" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc7317a6dff2.png" style="width: 519px"/></figure></div><div id="unMXbBWkHbEh4r6HKiDMr8" class="wolai-block wolai-text"><div><span class="inline-wrap">将<span class="jill"></span>w<span class="jill"></span>代入<span class="jill"></span>L<span class="jill"></span>化简，便得到其对偶问题：</span></div></div><div id="hwDVoyEEDwSAjkmRigoefS" class="wolai-block wolai-center"><figure style="width: 100%"><img src="https://i.loli.net/2018/10/17/5bc7317ab6646.png" style="width: 655px"/></figure></div><div id="73Kc79S4SZA3TogWkXnL5J" class="wolai-block wolai-text"><div><span class="inline-wrap">将“软间隔”下产生的对偶问题与原对偶问题对比可以发现：新的对偶问题只是约束条件中的<span class="jill"></span>α<span class="jill"></span>多出了一个上限<span class="jill"></span>C，其它的完全相同，因此在引入核函数处理线性不可分问题时，便能使用与“硬间隔”支持向量机完全相同的方法。</span></div></div><div id="qDDfYUwGuEz4YEN2ANU4Rh" class="wolai-block wolai-text"><div><span class="inline-wrap">----在此<span class="jill"></span>SVM<span class="jill"></span>就介绍完毕。</span></div></div></article><footer></footer></body></html></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">tiaotiaohu</div><div class="author-info__description">跳跳虎的酒吧</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/tiaotiaohu98/"><i class="fab fa-github"></i><span>我的 Github</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">跳跳虎的个人博客</div></div><div class="card-widget"><div class="item-headline"><i></i><span></span></div><div class="item-content"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#vSCYiiP6CwnqDt4iDTbJkD"><span class="toc-number">1.</span> <span class="toc-text">6、支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ojzQdbYypTzqJfCzEW9XQx"><span class="toc-number">1.0.1.</span> <span class="toc-text">6.1.2 几何间隔</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#47hJou18oQfsLoneu6769g"><span class="toc-number">1.1.</span> <span class="toc-text">6.3 从原始优化问题到对偶问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#t6Mf1DWN1Vms2qQ6LQ9wva"><span class="toc-number">1.2.</span> <span class="toc-text">6.4 核函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2tNf1KaJcSqnsq6VEXvsXJ"><span class="toc-number">1.3.</span> <span class="toc-text">6.5 软间隔支持向量机</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(10)--%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" title="第10节_集成学习"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第10节_集成学习"/></a><div class="content"><a class="title" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(10)--%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" title="第10节_集成学习">第10节_集成学习</a><time datetime="2022-08-29T07:18:04.072Z" title="发表于 2022-08-29 15:18:04">2022-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(11)--%E8%81%9A%E7%B1%BB/" title="第11节_聚类"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第11节_聚类"/></a><div class="content"><a class="title" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(11)--%E8%81%9A%E7%B1%BB/" title="第11节_聚类">第11节_聚类</a><time datetime="2022-08-29T07:18:04.072Z" title="发表于 2022-08-29 15:18:04">2022-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(13)--%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E4%B8%8E%E7%A8%80%E7%96%8F%E5%AD%A6%E4%B9%A0/" title="第13节_特征选择与稀疏学习"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第13节_特征选择与稀疏学习"/></a><div class="content"><a class="title" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(13)--%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E4%B8%8E%E7%A8%80%E7%96%8F%E5%AD%A6%E4%B9%A0/" title="第13节_特征选择与稀疏学习">第13节_特征选择与稀疏学习</a><time datetime="2022-08-29T07:18:04.072Z" title="发表于 2022-08-29 15:18:04">2022-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(15)--%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" title="第15节_半监督学习"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第15节_半监督学习"/></a><div class="content"><a class="title" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(15)--%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" title="第15节_半监督学习">第15节_半监督学习</a><time datetime="2022-08-29T07:18:04.072Z" title="发表于 2022-08-29 15:18:04">2022-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(14)--%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/" title="第14节_计算学习理论"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第14节_计算学习理论"/></a><div class="content"><a class="title" href="/2022/08/29/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8AMachine%20Learning%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(14)--%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/" title="第14节_计算学习理论">第14节_计算学习理论</a><time datetime="2022-08-29T07:18:04.072Z" title="发表于 2022-08-29 15:18:04">2022-08-29</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">机器学习笔记</span><span class="card-category-list-count">17</span></a></li>
            </ul></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/08/"><span class="card-archive-list-date">八月 2022</span><span class="card-archive-list-count">17</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/04/"><span class="card-archive-list-date">四月 2022</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站信息</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">aside.card_webinfo :</div><div class="item-count">18</div></div><div class="webinfo-item"><div class="item-name">aside.card_webinfo.runtime :</div><div class="item-count" id="runtimeshow" data-publishDate="2022-04-07T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">aside.card_webinfo.last_push_date :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-08-30T15:22:57.378Z"></div></div></div></div><div class="card-widget user-map" id="user-map"><div class="item-headline"><i class="fas fa-heartbeat"></i><span>访客地图</span></div><div class="item-content"><script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=5V2tOKp8qAdRM-i8eu7ETTO9ugt5uKbbG-U7Yj8uMl8"></script></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By tiaotiaohu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">欢迎来到我的博客!!!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>